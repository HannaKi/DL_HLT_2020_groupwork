{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "This project is about text classification. You will develop a text classification system that identifies different kinds of online texts, such as news, blogs and opinionated texts. We will refer to these text categories as registers. If you want to learn more about online registers and their automatic identification, you can read, e.g., our paper [Toward Multilingual Identification of Online Registers] (https://www.aclweb.org/anthology/W19-6130/).\n",
    "\n",
    "# Data and register labels\n",
    "The data for this project consist of ~7500 documents with manual annotations on their register. You can download it from TODO. The documents are based on a (almost) random sample of the Finnish Internet. The registers are identified using a relatively detailed, hierarchical taxonomy. The taxonomy consists of 8 main categories that are divided into a large number of subregisters. The taxonomy is described at the end of this page. The table includes also the abbreviations that are used in the data.\n",
    "\n",
    "The challenge with online documents is that it is not always easy to identify the specific registers categories of the documents. Furthermore, another issue is that a document may display characteristics of several registers. For instance, a blog post may simultaneously seem like a product review. To deal with these challenges, we have followed the following guidelines:\n",
    "* For each document, the annotators have aimed at marking the specific subregister category. When this is possible, the document has two register labels: the subregister label and the main register label to which the subregister belongs. For instance, a document annotated as a news article would have the label NE for News and the corresponding higher level register label NA for Narrative. \n",
    "* In some cases, the document does not seem to fit any of the subregisters. In this case, the document can be given only one label: the main register label, such as NA for Narrative. \n",
    "* Some documents may display characteristics of several register categories. In this case, the annotator can mark several register labels for one single document. Consequently, the document may have up to four labels. This would be the case case if a document is annotated both as a Personal blog (subregister label PB + corresponding higher level register label NA) and Review (subregister label RV + corresponding higher level register label OP).\n",
    "\n",
    "# Milestone 1.1: Bag-of-words classifier (multi-class)\n",
    "Train a bag-of-words classifier to predict the register categories. In this milestone, the setting is multi-class, so the register label combinations form the classes, e.g. NA_NE and NA_NE_OP_OB. Evaluate your model and report your results with different hyperparameters.\n",
    "\n",
    "# Milestone 1.2: Recurrent Neural Network Classifier (multi-class)\n",
    "Modify your codes from milestone 1.1 to use recurrent neural networks (e.g. LSTM or biLSTM) in the classifier. Evaluate your model and report your results with different hyperparameters.\n",
    "\n",
    "# Milestone 2.1: Deep contextual representations with Bert (multi-class)\n",
    "Train a Bert classifier to predict the register categories. Similar to Milestone 1, the setting is multi-class, and the evaluations should include results with different hyperparameters.\n",
    "\n",
    "# Milestone 2.2: Error analysis\n",
    "Compare the errors made by the classifiers you have trained from milestones 1 and 2.1. Are there any patterns? How do the errors one model makes differ from those made by another.\n",
    "\n",
    "# Milestone 3.1: Bert (multi-LABEL)\n",
    "Train two multi-label classifiers, one using non-deep contextual representations, the other using Bert. In this setting, each label is assigned independently. Do hyperparameter optimization on these classifiers.\n",
    "\n",
    "# Milestone 3.2: Model comparison\n",
    "Compare the results of these two classifiers. Do the two models predict in the same way? Analyze the predictions in terms of label-specific differences.\n",
    "\n",
    "# Register classes and abbreviations\n",
    "\n",
    "NA Narrative\n",
    "\n",
    "* NE NA    New reports / news blogs\n",
    "* SR NA    Sports reports\n",
    "* PB NA    Personal blog\n",
    "* HA NA    Historical article\n",
    "* FC NA    Fiction\n",
    "* TB NA    Travel blog\n",
    "* CB NA    Community blogs\n",
    "* OA NA    Online article\n",
    "\n",
    "OP  Opinion\n",
    "* OB OP  Personal opinion blogs\n",
    "* RV OP  Reviews\n",
    "* RS OP  Religious blogs/sermons\n",
    "* AV OP  Advice\n",
    "\n",
    "IN Informational description\n",
    "* JD IN  Job description\n",
    "* FA IN  FAQs\n",
    "* DT IN  Description of a thing\n",
    "* IB IN  Information blogs\n",
    "* DP IN  Description of a person\n",
    "* RA IN  Research articles\n",
    "* LT IN  Legal terms / conditions\n",
    "* CM IN  Course materials\n",
    "* EN IN  Encyclopedia articles\n",
    "* RP IN  Report\n",
    "\n",
    "ID Interactive discussion\n",
    "* DF ID  Discussion forums\n",
    "* QA ID  Question-answer forums\n",
    "\n",
    "HI  How-to/instructions\n",
    "* RE HI  Recipes\n",
    "\n",
    "IP IG  Informational persuasion\n",
    "* DS IG  Description with intent to sell\n",
    "* EB IG  News-opinion blogs / editorials\n",
    "\n",
    "Lyrical LY\n",
    "* PO LY  Poems\n",
    "* SL LY  Songs\n",
    "\n",
    "Spoken SP\n",
    "* IT SP Interviews\n",
    "* FS SP Formal speeches\n",
    "\n",
    "Others OS\n",
    "* MT OS Machine-translated / generated texts\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
